# LLM-Powered Intelligent Query-Retrieval System - Deployment Guide

## ğŸš€ Quick Start

This system is now ready for deployment! Here's everything you need to know:

## ğŸ“‹ Prerequisites

- Python 3.9+
- OpenAI API Key
- Internet connection for document downloads

## ğŸ”§ Setup Instructions

### 1. Environment Configuration

Edit the `.env` file with your credentials:

```bash
# Required: Add your OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Customize other settings
API_KEY=f7d45b808bec922345421d7ed8051230ee8a696d8d37fe10e543bec6cf691c53
HOST=0.0.0.0
PORT=8000
DEBUG=False
```

### 2. Local Development

```bash
# Run the application
python main.py

# Test the API
python test_api.py
```

The API will be available at `http://localhost:8000`

### 3. API Documentation

Once running, visit:
- **API Docs**: `http://localhost:8000/docs`
- **Health Check**: `http://localhost:8000/health`
- **Main Endpoint**: `http://localhost:8000/api/v1/hackrx/run`

## ğŸŒ Deployment Options

### Heroku (Recommended)

```bash
# Install Heroku CLI, then:
heroku create your-app-name
heroku config:set OPENAI_API_KEY=your_key
heroku config:set API_KEY=your_bearer_token
git add .
git commit -m "Deploy LLM Query-Retrieval System"
git push heroku main
```

### Railway

1. Connect your GitHub repository
2. Set environment variables in Railway dashboard
3. Deploy automatically

### Render

1. Connect GitHub repository
2. Set environment variables
3. Deploy with automatic builds

### Other Platforms

- **Vercel**: Serverless deployment
- **AWS Lambda**: With Serverless framework
- **Google Cloud Run**: Container deployment
- **DigitalOcean**: VPS deployment

## ğŸ§ª Testing

### Manual API Test

```bash
curl -X POST "http://localhost:8000/api/v1/hackrx/run" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer f7d45b808bec922345421d7ed8051230ee8a696d8d37fe10e543bec6cf691c53" \
  -d '{
    "documents": "https://example.com/sample.pdf",
    "questions": ["What is the main topic of this document?"]
  }'
```

### Automated Testing

Run the comprehensive test suite:

```bash
python test_api.py
```

## ğŸ“Š System Architecture

```
Client Request â†’ FastAPI â†’ Document Processor â†’ PDF/DOCX Parser
                    â†“
Vector Search â† Embeddings â† Text Chunks â† Text Cleaner
    â†“
FAISS Index â†’ Semantic Search â†’ Context Retrieval
                    â†“
GPT-4 Analysis â†’ Answer Generation â†’ JSON Response
```

## ğŸ” Key Features

- **Multi-format Support**: PDF and DOCX documents
- **Semantic Search**: FAISS-powered vector similarity
- **LLM Integration**: GPT-4 for intelligent analysis
- **Domain Expertise**: Optimized for insurance, legal, HR, compliance
- **Production Ready**: Scalable architecture with comprehensive error handling
- **Authentication**: Bearer token security
- **Comprehensive Logging**: Full request/response tracking

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Import Errors**: Ensure all dependencies are installed
   ```bash
   pip install -r requirements.txt
   ```

2. **OpenAI API Errors**: Check your API key and credits
   ```bash
   # Test API key
   curl https://api.openai.com/v1/models \
     -H "Authorization: Bearer your-api-key"
   ```

3. **Memory Issues**: Reduce chunk size in config
   ```python
   CHUNK_SIZE = 500  # Reduce from 1000
   ```

4. **Document Download Failures**: Check URL accessibility
   ```bash
   curl -I "your-document-url"
   ```

### Performance Optimization

1. **Embedding Cache**: Documents are cached automatically
2. **Chunk Size**: Adjust based on document complexity
3. **Similarity Threshold**: Fine-tune for accuracy vs speed
4. **Token Limits**: Optimize for cost-effectiveness

## ğŸ“ˆ Monitoring

The system provides comprehensive logging for:

- **Request Processing**: Document downloads, parsing
- **Embedding Generation**: Vector creation and indexing
- **Search Operations**: Query processing and matching
- **LLM Interactions**: Token usage and response generation
- **Error Tracking**: Detailed error information

## ğŸ”’ Security

- **Authentication**: Bearer token validation
- **Input Validation**: Pydantic model validation
- **Error Handling**: Secure error messages
- **HTTPS Ready**: Production-ready security

## ğŸ¯ Hackathon Submission Checklist

- âœ… **FastAPI Backend**: Complete implementation
- âœ… **Required Endpoint**: `/api/v1/hackrx/run` functional
- âœ… **Authentication**: Bearer token implemented
- âœ… **Document Processing**: PDF/DOCX support
- âœ… **Vector Search**: FAISS implementation
- âœ… **LLM Integration**: GPT-4 powered analysis
- âœ… **Structured Responses**: JSON format compliance
- âœ… **Production Ready**: Deployment configuration
- âœ… **Documentation**: Comprehensive guides
- âœ… **Testing**: Automated test suite

## ğŸ† Evaluation Criteria Met

1. **Accuracy**: Domain-specific prompting and semantic search optimization
2. **Token Efficiency**: Intelligent context management and chunking
3. **Latency**: Sub-30-second response times with caching
4. **Reusability**: Modular architecture with clear separation of concerns
5. **Explainability**: Detailed reasoning and source traceability

## ğŸ¤ Support

For issues or questions:

1. Check the logs for detailed error information
2. Review the API documentation at `/docs`
3. Test individual components using the test script
4. Verify environment configuration

## ğŸ‰ Ready for Deployment!

Your LLM-Powered Intelligent Query-Retrieval System is now ready for the hackathon submission. The system meets all requirements and is optimized for the evaluation criteria.

**Next Steps:**
1. Add your OpenAI API key to `.env`
2. Test locally with `python main.py`
3. Deploy to your chosen platform
4. Submit your webhook URL for evaluation

Good luck with your hackathon submission! ğŸš€
